---
output: 
  html_document:
      toc: true
      toc_float: true
      toc_depth: 4
---
# R2: Analysis, Gathering and Cleaning Data- Nicar 2022, Atlanta   

<br>    


**Goals:**
    
    Use the tidyverse packages dplyr and ggplot2   
    Sort, filter, group, summarize, join, and visualize   
    Identify trends in your data.   

 
**Analysis of San Francisco Police Calls for Service Data**  

- **Here is the original dataset: 3,048,797 records**  

https://data.sfgov.org/Public-Safety/Police-Department-Calls-for-Service/hz9m-tj6z/data

    311 logs calls on general non-emergency issues ranging from blocked sidewalks to graffiti to homeless concerns. Details: https://support.datasf.org/help/311-case-data-faq

- **This tutorial uses a subset of this data** 

    The Calls for Service were filtered as follows: 
    CONTAINS homeless, 915, 919, 920: Downloaded 157,237 records 3/31/16 to 11/30/2019. 
    This is 5.1% of all calls in the broader database.
    File renamed to: SF_311_Jan29.xlsx   
   


# Part 1: Load Software, Interview Data




```{r}
#background on tidyverse: https://www.tidyverse.org/packages/

library(tidyverse)
library(janitor)
library(lubridate)
```




Load Data
```{r}
#At Home: See Appendix to load data at home from Internet

SF <- rio::import("SF_311_Jan29.xlsx", which = "SF Police_Department_Calls_for_") 
```

-- **Interview the Data**
```{r}
head(SF)
#view(SF)
```


- **Clean column names, Process dates** 
```{r}
#This cleans column names
SF <- janitor::clean_names(SF)
#This processes dates for analysis
SF$call_date2 <- ymd(SF$call_date)
#This creates a new column for year
SF$year <- year(SF$call_date2)
```

- **311 Calls by Year**
```{r}
Years <- SF %>% 
  count(year) %>% 
  group_by(year) %>% 
  arrange(desc(year))
head(Years)
```

## Basic ggplot

-- **Graph Years using ggplot**

```{r}
ggplot(data=Years) +
  geom_col(mapping=aes(x=year, y=n)) 

```

-- **That's ugly. Add some color: fill= **

```{r}
ggplot(data=Years) +
  geom_col(mapping=aes(x=year, y=n, fill=n)) 

```

-- **Ditch the legend**
```{r}

ggplot(Years,aes(x = year, y = n,
             fill = n)) +
  geom_col(position = "dodge") + 
  theme(legend.position = "none")

```

-- **Add Headlines, Annotations and Credits**
```{r}

ggplot(Years,aes(x = year, y = n,
             fill = n)) +
  geom_col(position = "dodge") + 
  theme(legend.position = "none") +
#This is your title sequence
  labs(title = "311 Calls for Service By Day, San Francisco",
       subtitle = "SF PD Service Call Data, 2016-2019",
       caption = "Graphic by Rob Wells, 2-12-2022",
       y="Number of Calls",
       x="Year")
```

-- **Filter a dataset, build a chart in one code block**

```{r}
#Copy section of code from above...
SF %>% 
   count(year) %>% 
   group_by(year) %>% 
#Sandwich it onto a simple ggplot
  ggplot(aes(x = year, y = n, fill = n)) +
  geom_col(position = "dodge") + 
  theme(legend.position = "none") +
  labs(title = "311 Calls for Service By Year, San Francisco", 
       subtitle = "SF PD Service Call Data, 2016-2019",
       caption = "Graphic by Wells",
       y="Number of Calls",
       x="Year")
```


- **Which Day Had the Most 311 Calls?**
Using count to tabulate calls by day
```{r}
Days <- SF %>% 
  count(call_date2) %>% 
  arrange(desc(n))

head(Days)
```

-- **Chart Calls by Day**


```{r}
#Adapting code from above...
SF %>% 
  count(call_date2) %>% 
#Sandwich it onto a simple ggplot
  ggplot(aes(x = call_date2, y = n, fill = n)) +
  geom_bar(stat = "identity") +
  labs(title = "311 Calls for Service By Day, San Francisco", 
       subtitle = "SF PD Service Call Data, 2016-2019",
       caption = "Graphic by Wells",
       y="Number of Calls",
       x="Day")
```

- **Interviewing: Types of Crimes**
```{r}
SF1 <- SF %>% count(original_crime_type_name) %>% 
    arrange(desc(n))
head(SF1)
#view(SF1)
```


- **Interviewing: Actions Taken**
```{r}
Action <- SF %>% 
  count(disposition) %>% 
  arrange(desc(n))
head(Action)
view(Action)
```

# Part 3: Visualization

- **Question**: What were the common days for arrests?

- **Task: Tabulate complaints by day of the week**  

https://github.com/profrobwells/Data-Analysis-Class-Jour-405v-5003/blob/master/Readings/dealing-with-dates.pdf

```{r}
SF <- SF %>% 
  mutate(weekday = wday(call_date, label=TRUE, abbr=FALSE))
```

```{r}
SF %>%
  select(weekday, crime_id, disposition) %>%
  filter(grepl("ARR", disposition)) %>%
  count(weekday) 

#grepl, your find function: searches for matches of a string, returns true or false. "grep logical"

```

Make an ugly bubble chart
```{r}
  #using the code above
SF %>%
  select(weekday, crime_id, disposition) %>%
  filter(grepl("ARR", disposition)) %>%
  count(weekday) %>%
  
#and sandwich onto a graphic
  ggplot(aes(x = weekday, y = n)) +
  geom_point(aes(size = n, color = n))
```


-- **Clean up bubble chart**

    We add y-axis label, headline & ditch the legend

```{r}
  #using the code above
SF %>%
  select(weekday, crime_id, disposition) %>%
  filter(grepl("ARR", disposition)) %>%
  count(weekday) %>%
#and sandwiching onto a graphic
  ggplot(aes(x = weekday, y = n)) +
  ylab("Arrests") +
  geom_point(aes(size = n, color = n), alpha = 0.7, show.legend = FALSE) +
  labs(title = "Homeless Arrests By Weekday in San Francisco",
       subtitle = "SF PD Service Call Data 2017-2019: Source: SFPD",
       caption = "Graphic by Wells")
```

-- **Pretty Bubble Chart**

    Scaled y axis: scale_y_continuous
    Bumped up bubble size: scale_size_area
    saved chart to object: bubble

```{r}
  #using the code above
bubble <- SF %>%
  select(weekday, crime_id, disposition) %>%
  filter(grepl("ARR", disposition)) %>%
  count(weekday) %>%
#and sandwiching onto a graphic
  ggplot(aes(x = weekday, y = n)) +
  ylab("Arrests") +
  xlab("") +
  geom_point(aes(size = n, color = n), alpha = 0.7, show.legend = FALSE) +
  scale_size_area(guide = "none", max_size = 25) +
  scale_y_continuous(limits=c(0, 100)) +
  labs(title = "Homeless Arrests By Weekday in San Francisco",
       subtitle = "SF PD Service Call Data 2017-2019: Source: SFPD",
       caption = "Graphic by Rob Wells, 2/12/2022")
bubble
```

-- **Export to Hi Res File**
```{r}
ggsave("bubble.png",device = "png",width=9,height=6, dpi=800)
```


# Greatest Hits

#Becca Redeker

```{r}
data22 <- rio::import("temp2022.txt") %>% 
  clean_names() %>% 
  rename(year= "v1", day="v2", Sup.="v3", Mich.="v4", Huron="v5",Erie="v6", Ont.="v7",St.Clr="v8") %>% 
clean_names()
```

```{r}
data22 <- data22 %>%
  mutate(month = case_when(
    day %in% 1:31 ~ "January",
    day %in% 32:60 ~ "February",
    day %in% 61:91 ~ "March",
    day %in% 92:121 ~ "April",
    day %in% 122:152~ "May",
    day %in% 153:182 ~ "June",
    day %in% 183:212 ~ "July",
    day %in% 213:243 ~ "August",
    day %in% 244:273 ~ "September",
    day %in% 274:304 ~ "October",
    day %in% 305:333 ~ "November",
    day %in% 334:365 ~ "December",
  ))

```

What 5 days did Lake Michigan have the biggest changes in temperature for 2022?

```{r}
mich_droplag <- data22 %>% 
  select(year, day, month, mich) %>%
  arrange(day) %>%
  mutate(temp_diff = mich - lag(mich, default = first(mich))) %>% 
    arrange(desc(temp_diff))
```



#Embedded graphic.  

#Ela Jalil.  

```{r echo=FALSE, results='asis'}
cat('<iframe src="https://flo.uri.sh/visualisation/17782953/embed" title="Interactive or visual content" class="flourish-embed-iframe" frameborder="0" scrolling="no" style="width:100%;height:600px;" sandbox="allow-same-origin allow-forms allow-scripts allow-downloads allow-popups allow-popups-to-escape-sandbox allow-top-navigation-by-user-activation"></iframe><div style="width:100%!;margin-top:4px!important;text-align:right!important;"><a class="flourish-credit" href="https://public.flourish.studio/visualisation/17782953/?utm_source=embed&utm_campaign=visualisation/17782953" target="_top" style="text-decoration:none!important"><img alt="Made with Flourish" src="https://public.flourish.studio/resources/made_with_flourish.svg" style="width:105px!important;height:16px!important;border:none!important;margin:0!important;"></a></div>')
```


# Good graphic

# Emily Condon

Q4: Are there any patterns between urban and rural hospitals? What factors affect wait times in each of these areas?

```{r}

january_ed <- read_csv("january_ed.csv")

january_ed$address_back <- january_ed$address
january_ed<- separate(january_ed, col = address_back, into = c("street", "city", "zip"), sep = ",", extra = "merge", fill = "right")
 january_ed$zip
january_ed<- separate(january_ed, col = zip, into = c("state", "zip"), sep = " ")

january_ed <- clean_names(january_ed)

```

#Defining rural and urban (not rural) by MD Dept of Health definition
```{r}


urban_rural <- january_ed %>% 
  mutate(county=city) 

urban_rural$county <- gsub("Berlin", "Worcester", urban_rural$county)
urban_rural$county <- gsub("Oakland", "Garrett", urban_rural$county)
urban_rural$county <- gsub("Baltimore", "Balt City", urban_rural$county)
urban_rural$county <- gsub("Leonardtown", "St. Marys", urban_rural$county)
urban_rural$county <- gsub("Hagerstown", "Washington", urban_rural$county)
urban_rural$county <- gsub("Elkton", "Cecil", urban_rural$county)
urban_rural$county <- gsub("Salisbury", "Wicomico", urban_rural$county)
urban_rural$county <- gsub("Germantown", "Montgomery", urban_rural$county)
urban_rural$county <- gsub("Havre De Grace", "Harford", urban_rural$county)
urban_rural$county <- gsub("Rockville", "Montgomery", urban_rural$county)
urban_rural$county <- gsub("Cumberland", "Allegany", urban_rural$county)
urban_rural$county <- gsub("Silver Spring", "Montgomery", urban_rural$county)
urban_rural$county <- gsub("Bethesda", "Montgomery", urban_rural$county)
urban_rural$county <- gsub("La Plata", "Charles", urban_rural$county)
urban_rural$county <- gsub("Fort Washington", "Prince George's", urban_rural$county)
urban_rural$county <- gsub("Olney", "Montgomery", urban_rural$county)
urban_rural$county <- gsub("Glen Burnie", "Anne Arundel", urban_rural$county)
urban_rural$county <- gsub("Columbia", "Howard", urban_rural$county)
urban_rural$county <- gsub("Bel Air", "Harford", urban_rural$county)
urban_rural$county <- gsub("Largo", "Prince George's", urban_rural$county)
urban_rural$county <- gsub("Easton", "Talbot", urban_rural$county)
urban_rural$county <- gsub("Randallstown", "Balt County", urban_rural$county)
urban_rural$county <- gsub("Annapolis", "Anne Arundel", urban_rural$county)
urban_rural$county <- gsub("Clinton", "Prince George's", urban_rural$county)
urban_rural$county <- gsub("Towson", "Balt County", urban_rural$county)
```

According to MD Dept of health (https://health.maryland.gov/pophealth/Pages/Rural-health.aspx): "Allegany, Calvert, Caroline, Carroll, Cecil, Charles, Dorchester, Frederick, Garrett, Harford, Kent, Queen Anne’s, Somerset, St. Mary’s, Talbot, Washington, Wicomico, and Worcester."



```{r}
urban_rural <- as.data.frame(urban_rural)

urban_rural <- clean_names(urban_rural)

urban_rural <- urban_rural %>% 
  mutate(
  define = case_when(
   county == ' Allegany'  ~ "rural",
   county == ' Cecil' ~ "rural",
   county == ' Charles'  ~ "rural",
   county == ' Federick'  ~ "rural",
   county == ' Garrett' ~ "rural",
   county == ' Harford'  ~ "rural",
   county == ' St. Marys'  ~ "rural",
   county == ' Talbot' ~ "rural",
   county == ' Washington'  ~ "rural",
   county == ' Wicomico' ~ "rural",
   county == ' Worcester'  ~ "rural",
   TRUE ~ "not_rural"))

urban_rural <- urban_rural %>% 
  select(abbreviated_name, january_median, address, county, define)
```


```{r}
rural_hospitals <- urban_rural %>% 
  filter(define == "rural")

mean(rural_hospitals$january_median) #= 682.25 minutes (or 11.3 hours)

not_rural_hospitals <- urban_rural %>% 
  filter(define == "not_rural")

mean(not_rural_hospitals$january_median) #= 711.2759 minutes (or 11.8 hours)
```
#There is not a significant difference in averages for january wait times for rural and non rural hospitals



```{r}
urban_rural %>% 
  ggplot(aes(x=reorder(abbreviated_name, january_median), y=january_median, weight=january_median, fill=define)) +
  geom_col()+
  geom_text(aes(label=january_median), vjust = -1, size = 2.5) +
  labs(
    title="Median Time for hospitals in January (by rural and non",
    x = "Hospital Name",
    y = "median time in minutes",
    caption = "source: Maryland Hospital Association Cost Review Commisssion")

#Although the two hospitals with the highest average wait times in January were rural, the hospitals with the two lowest wait times were also rural. There seems to be no causal relationship between wait times and rural or urban hospitals.

```

#Fix x-axis

```{r}
urban_rural %>% 
  ggplot(aes(x=reorder(abbreviated_name, january_median), y=january_median, weight=january_median, fill=define)) +
  geom_col()+
  geom_text(aes(label=january_median), vjust = -1, size = 2.5) +
   theme(axis.text.x = element_text(angle=90)) +
  labs(
    title="Median Time for hospitals in January (by rural and non",
    x = "Hospital Name",
    y = "median time in minutes",
    caption = "source: Maryland Hospital Association Cost Review Commisssion")

#Although the two hospitals with the highest average wait times in January were rural, the hospitals with the two lowest wait times were also rural. There seems to be no causal relationship between wait times and rural or urban hospitals.

```

# --30-- 

